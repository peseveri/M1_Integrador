# Proyecto de AnÃ¡lisis y PreparaciÃ³n de Datos para E-commerce
## Avance 1
## ğŸš€ VisiÃ³n General del Proyecto

Este proyecto es el primer avance en la mejora del sistema de reportes de una empresa de e-commerce. Como parte del equipo de datos, mi rol fue analizar y comprender las fuentes de datos disponibles (archivos CSV) para establecer las bases de un modelado de datos robusto. El enfoque principal estuvo en la **carga de datos en una base de datos relacional**, la **evaluaciÃ³n de su calidad** y la **detecciÃ³n de inconsistencias**, sentando las bases para futuras transformaciones y anÃ¡lisis.

---

## ğŸ¯ Objetivos

* **Configurar el Entorno de Base de Datos**: Establecer una base de datos relacional (MySQL).
* **Crear y Cargar Tablas**: Generar la estructura de tablas y poblar la base de datos con datos de archivos CSV.
* **Preparar y Transformar Datos**: Identificar y transformar columnas con datos semi-estructurados a un formato estructurado.
* **Explorar Datos**: Realizar un anÃ¡lisis exploratorio de datos (EDA) utilizando SQL y Python (ORM).
* **Identificar Estructura y Relaciones**: Determinar atributos clave, llaves primarias y forÃ¡neas, y otras relaciones importantes para preguntas de negocio.
* **Evaluar la Calidad de los Datos**: Detectar y documentar problemas de calidad de datos, proponiendo posibles soluciones.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

* **Base de Datos**: MySQL
* **Lenguajes**: SQL, Python
* **LibrerÃ­as Python**:
    * `pandas`
    * `SQLAlchemy`
    * `python-dotenv`
    * `pymysql`
    * `matplotlib`
    * `seaborn`
* **Entorno Virtual**: `venv`

---

## ğŸ“¦ Estructura del Proyecto
â”œâ”€â”€ Avance1/
â”‚   â”œâ”€â”€ csv/
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â”‚   â”œâ”€â”€ load_data.sql
â”‚   â”‚   â””â”€â”€ check_data.sql
â”‚   â”œâ”€â”€ estructura_relaciones.md
â”‚   â”œâ”€â”€ detectar_semiestructurados.py
â”‚   â””â”€â”€ eda_orm.ipynb
â”œâ”€â”€ Avance2/
â”‚   â”œâ”€â”€ ER.png
â”‚   â””â”€â”€ modelo_dimensional.md
â”œâ”€â”€ Avance3/
â”‚   â””â”€â”€ ecommerceDBT/                    # Carpeta principal del proyecto DBT
â”‚       â”œâ”€â”€ dbt_project.yml              # Archivo de configuraciÃ³n del proyecto DBT
â”‚       â”œâ”€â”€ packages.yml                 # Define los paquetes DBT de terceros a instalar
â”‚       â”œâ”€â”€ packages-lock.yml            # Generado automÃ¡ticamente, registra las versiones exactas de los paquetes instalados
â”‚       â””â”€â”€ models/                      # Contiene todos tus modelos SQL de DBT
â”‚           â”œâ”€â”€ staging/                 # Capa Bronze: Limpieza y selecciÃ³n bÃ¡sica
â”‚           â”‚   â”œâ”€â”€ stg_usuarios.sql
â”‚           â”‚   â”œâ”€â”€ stg_categorias.sql
â”‚           â”‚   â”œâ”€â”€ stg_productos.sql
â”‚           â”‚   â”œâ”€â”€ stg_ordenes.sql
â”‚           â”‚   â”œâ”€â”€ stg_detalle_ordenes.sql
â”‚           â”‚   â”œâ”€â”€ stg_metodos_pago.sql
â”‚           â”‚   â”œâ”€â”€ stg_historial_pagos.sql
â”‚           â”‚   â”œâ”€â”€ stg_reseÃ±as.sql
â”‚           â”‚   â””â”€â”€ stg_direcciones_envio.sql
â”‚           â”‚
â”‚           â”œâ”€â”€ intermediate/            # Capa Silver: Transformaciones intermedias y SCDs
â”‚           â”‚   â”œâ”€â”€ int_productos_scd.sql
â”‚           â”‚   â”œâ”€â”€ int_usuarios_scd.sql
â”‚           â”‚   â”œâ”€â”€ int_base_ventas.sql
â”‚           â”‚   â”œâ”€â”€ int_base_pagos.sql
â”‚           â”‚   â””â”€â”€ int_base_reseÃ±as.sql
â”‚           â”‚
â”‚           â””â”€â”€ gold/                    # Capa Gold: Modelos dimensionales finales (hechos y dimensiones)
â”‚               â”œâ”€â”€ dim_tiempo.sql
â”‚               â”œâ”€â”€ dim_usuario.sql
â”‚               â”œâ”€â”€ dim_producto.sql
â”‚               â”œâ”€â”€ dim_categoria.sql
â”‚               â”œâ”€â”€ dim_metodo_pago.sql
â”‚               â”œâ”€â”€ fact_ventas.sql
â”‚               â”œâ”€â”€ fact_pagos.sql
â”‚               â”œâ”€â”€ fct_reseÃ±as.sql
â”‚               â”‚
â”‚               â””â”€â”€ schema.yml             # Un Ãºnico archivo schema.yml para todos los modelos Gold
|â”€â”€â”€ .env
|â”€â”€â”€ .gitignore
|â”€â”€â”€ requirements.txt


---

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n

1. **Clonar el repositorio y crear entorno virtual**:

    Clonar el repositorio: git clone <URL_DEL_REPOSITORIO> cd Avance1
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate

2. **Instalar dependencias**:
    ```bash
    pip install -r requirements.txt
    ```


3. **Configurar archivo .env**:
    ```env
    DB_USER=tu_usuario
    DB_PASSWORD=tu_contraseÃ±a
    DB_HOST=localhost
    DB_PORT=3306
    DB_NAME=ecommercedb
    ```

4. ## Configurar la base de datos:
    AsegÃºrate de tener MySQL 8.0 o superior instalado y en ejecuciÃ³n. Copia los archivos CSV a la ruta especificada en secure_file_priv de MySQL (por ejemplo, C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/). Para verificar esta ruta, ejecuta: SHOW VARIABLES LIKE 'secure_file_priv';

    Ejecuta el script SQL sql/create_tables.sql para crear la base de datos con las tablas y despues ejecutar sql/load_data para insertar la data desde el workbench y correr las queries.

5. ## Ejecutar el eda que realizara las validaciones de datos y el analisis exploratorio

    ```bash
    python eda_orm.ipynb
    ```

6. ## Estructura y Relaciones y exploracion de datos:
    Se encuentra detallado en el archivo estructura_relaciones.md
    Las queries para examinar los datos y detectar posibles inconsistencias estan en sql/check_data.sql

---
# Avance 2

Toda la informaciÃ³n del avance 2 estÃ¡ dentro de Avance2/ en donde se encuentra un documento explicando todo el modelo dimensional.

AclaraciÃ³n:  
Si desde la vista previa no se puede ver el entidad-relaciÃ³n, lo dejo adjuntado en el archivo ER.png

# Avance 3

## ğŸš€ ecommerceDBT - Un Data Warehouse para AnÃ¡lisis de E-commerce
Este proyecto implementa un Data Warehouse robusto y escalable para un sistema de e-commerce, utilizando dbt (data build tool) para todas las transformaciones de datos. El objetivo principal es consolidar datos de diversas fuentes transaccionales, limpiarlos, transformarlos y presentarlos en un formato optimizado para el anÃ¡lisis y la toma de decisiones estratÃ©gicas.

ğŸ¯ Objetivo del Proyecto
El principal objetivo de ecommerceDBT es construir un modelo de datos fÃ­sico en SQL que sirva como una fuente Ãºnica de verdad para el anÃ¡lisis de ventas, productos, usuarios y pagos. dbt facilita este proceso al permitirnos definir nuestras transformaciones como cÃ³digo SQL versionado, probado y documentado.

âœ¨ CaracterÃ­sticas Principales
ğŸ’¾ ImplementaciÃ³n del Modelo de Datos FÃ­sico en SQL (Gestionado por dbt)
En este proyecto, dbt es el encargado de la creaciÃ³n y materializaciÃ³n del modelo de datos fÃ­sico de la base de datos MySQL. No se requiere que crees manualmente las tablas del Data Warehouse (DimTiempo, FactVentas, etc.) con sentencias CREATE TABLE separadas. dbt, al ejecutar los modelos SQL, traduce automÃ¡ticamente la lÃ³gica de transformaciÃ³n en las sentencias DDL (Data Definition Language) necesarias para construir tus tablas y vistas en el esquema de destino configurado.

ğŸ”„ TransformaciÃ³n de Datos con dbt
Todos los procesos de transformaciÃ³n de datos se gestionan a travÃ©s de scripts SQL orquestados por dbt, siguiendo una arquitectura de capas (Medallion Architecture: Bronze, Silver, Gold):

Limpieza y NormalizaciÃ³n de Datos (Capa Staging/Bronze):
Los modelos en la carpeta staging/ son la primera parada para los datos brutos. AquÃ­ se realizan operaciones de limpieza mÃ­nimas, como renombrar columnas para mayor claridad y consistencia, y se ajustan tipos de datos bÃ¡sicos.

CreaciÃ³n de Tablas de Hechos y Dimensiones (Capas Intermediate/Silver y Gold):

Capa intermediate/ (Silver): AquÃ­ se aplican transformaciones mÃ¡s complejas, se unen datos de diferentes fuentes y se preparan las estructuras para las dimensiones y hechos finales. Es tambiÃ©n donde se implementa la lÃ³gica de Slowly Changing Dimensions.

Capa gold/ (Gold): Contiene los modelos finales de hechos y dimensiones, optimizados para el consumo analÃ­tico. Estos modelos desnormalizan intencionalmente ciertos atributos para mejorar el rendimiento de las consultas y la facilidad de uso para los analistas.

ImplementaciÃ³n de Slowly Changing Dimensions (SCD) con dbt:
Para capturar los cambios histÃ³ricos en atributos de dimensiones que evolucionan con el tiempo (como la direcciÃ³n de un usuario o el precio y stock de un producto), hemos implementado SCD Tipo 2 en modelos clave como dim_usuario y dim_producto. Esto se logra mediante la lÃ³gica incremental de dbt y la gestiÃ³n explÃ­cita de claves subrogadas (_sk), fechas de validez (fecha_inicio_validez_scd, fecha_fin_validez_scd) y el indicador es_actual.

ğŸ”— Manejo de Relaciones y GarantÃ­a de Integridad
dbt, aunque no impone restricciones de clave forÃ¡nea (FK) a nivel de base de datos directamente (una prÃ¡ctica comÃºn en Data Warehouses para optimizar el rendimiento de carga), nos permite manejar y validar la integridad referencial y la calidad de los datos de manera robusta a travÃ©s de:

Referencias (ref() y source()): Al usar {{ ref('nombre_modelo') }} para referenciar otros modelos dentro del proyecto, y {{ source('nombre_sistema_origen', 'nombre_tabla_origen') }} para las tablas fuente, dbt construye automÃ¡ticamente un Grafo Dirigido AcÃ­clico (DAG). Esto asegura que los modelos se construyan en el orden correcto de sus dependencias, garantizando que los datos necesarios estÃ©n disponibles antes de que un modelo dependiente se ejecute.

Tests de Integridad (schema.yml): Se definen tests explÃ­citamente en los archivos .yml (como models/gold/schema.yml) para verificar:

Unicidad y No Nulos: Para las claves primarias (unique, not_null).

Relaciones Referenciales: Para las claves forÃ¡neas (relationships), asegurando que todos los valores en una FK existan como PK en la tabla referenciada.

Tests Personalizados: Para lÃ³gicas de negocio mÃ¡s complejas o validaciones especÃ­ficas de SCD (ej., que solo haya una versiÃ³n es_actual por clave de negocio).

ğŸ“Š PresentaciÃ³n de Insights (Storytelling)
La capa gold/ de este proyecto estÃ¡ diseÃ±ada para ser la fuente principal para herramientas de Business Intelligence (BI) y anÃ¡lisis. Los datos transformados estÃ¡n listos para ser consultados y presentados en un formato que facilita la creaciÃ³n de narrativas y la extracciÃ³n de valor de negocio:

El Lunes es el Nuevo Viernes: Descubriendo los picos de ventas semanales para optimizar operaciones.

El Ã‰xito Silencioso de la CategorÃ­a 'Accesorios': Revelando el alto volumen de transacciones en categorÃ­as inesperadas.

DesafÃ­os en el Pipeline de Pagos: Identificando fugas de ingresos y oportunidades para mejorar la experiencia del cliente en el proceso de pago.

Clientes Fieles: El Motor Oculto de Nuestro Crecimiento: Cuantificando el valor de los clientes recurrentes y de alto gasto para enfocar estrategias de fidelizaciÃ³n.

## CÃ³mo Ejecutar el Proyecto

### Configurar profiles.yml:
AsegÃºrate de que el archivo ~/.dbt/profiles.yml (esto es adentro el disco C, adentro de tu usuario) estÃ© configurado con los detalles de tu conexiÃ³n a MySQL. El schema debe apuntar a tu base de datos de origen (EcommerceDB) para que dbt pueda leer las tablas raw_data.

Verificar dbt_project.yml
AsegÃºrate de que tu dbt_project.yml (en la raÃ­z de ecommerceDBT/) apunte al perfil correcto:

```yaml
name: 'ecommerceDBT'
version: '1.0.0'
profile: 'ecommerceDBT'

```
## Crear y Poblar Tablas de Origen:
Esto ya se realiza en el Avance 1

## Navegar al directorio del proyecto:
```bash
cd \M1_Integrador\Avance3\ecommerceDBT
```

## Instalar paquetes DBT, probar la conexion a la base, correr el DBT para realizar las transformaciones y ejecutar tests:
```bash
dbt deps
dbt debug
dbt run
dbt test
```


